# Neural Rendering and Dynamic Segmentation for Novel View Generation in 3D Scenes
I designed and implemented a complete system from scratch for neural rendering and novel view synthesis of 3D scenes. This work focuses on learning 3D scenes from images using optimizable volumetric radiance field models (such as Gaussian Splatting), with the goal of generating new scene perspectives from arbitrary viewpoints. The process begins by segmenting all images that compose the scene using object detection models like YOLO. Then, the objective is for the model to assign unique IDs to each pixel across the entire scene based on the segmented information from all images, enabling precise segmentation of every object within the 3D environment. This pipeline allows for object editing or removal both offline and in real time, achieving functional results in dynamic 3D scene segmentation.
